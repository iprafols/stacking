{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This tutorial aims to help you understand how to run the stacking code and to produce the necessary configuration files. This tutorial is prepared in the form of a jupyter notebook and should be used from a runnable interface (e.g. Jupyter Notebook Server, Virtual Studio Code, ...). The html view of this tutorial might provide incomplete and/or out of date information.\n",
    "\n",
    "# Running stacking\n",
    "\n",
    "In order to compute the composite spectra you need to run the code run_stacking. In this tutorial we are going to see how. If you are running this tutorial, you should have the package stacking installed. If you do not have it, then check the INSTALLATION section of the README\n",
    "\n",
    "The usage of the code is very simple. You just need to run from the command line \n",
    "\n",
    "`python run_stacking.py config.ini`\n",
    "\n",
    "where `config.ini` is a file with the desired configuration. \n",
    "\n",
    "Alternatively, you might want to run it from this jupyter notebook. In that case we do it like this:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import main function from stacking\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser('/path-to-stacking/stacking/bin/')) # this should be changed with your path to stacking\n",
    "from run_stacking import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it using a configuration file\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "        description=\"Compute the stack of a set of spectra\")\n",
    "\n",
    "parser.add_argument(\n",
    "'config_file',\n",
    "type=str,\n",
    "default=None,\n",
    "help=('Configuration file. To learn about all the available options '\n",
    "        'check the configuration tutorial in '\n",
    "        'tutorials/configuration_tutorial.ipynb'))\n",
    "\n",
    "print(\"WARNING: depending on the configuration file used this might take a lot of time\")\n",
    "main(parser.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions you might have:\n",
    "- What if I want to run without saving the configuration in a file? Unfortunatly this is not possible, at least for now. A different initialisation of the Config class would need to be coded.\n",
    "- Can I check the configuration of a previous run? Yes, the configuration for a given run is stored at a file named .config.ini in the output folder. \n",
    "- Can I use enviroment variables in my config arguments? Yes, they will be expanded before calling the specified file.\n",
    "- How can I create my own config? This is where things start to get tricky. We are now going to review how to build a configuration file, and the different options that are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build a config file: General structure\n",
    "\n",
    "The configuration file is nothing but a bunch of arguments that are structured in different sections. They are then parsed into usable format. To create a section simply type its name inside of square braquets:\n",
    "\n",
    "`[new section]`\n",
    "\n",
    "To add an argument to this section specify it simply:\n",
    "\n",
    "`my_string_argument = \"a string\"`\n",
    "\n",
    "`also_a_string_argument = another string`\n",
    "\n",
    "`my_int_argument = 1`\n",
    "\n",
    "`my_float_argument = 1.4`\n",
    "\n",
    "`my_bool_argument = True`\n",
    "\n",
    "`also_a_bool_argument = yes`\n",
    "`\n",
    "\n",
    "Note that the arguments and sections are not ordered, but all the arguments in a given section will need to be placed before the next section begins.\n",
    "\n",
    "Now that we have seen a short general introduction on config files, let's move to the more specific task at hand: how to build a config file for `picca.delta_extraction`. In this configuration we need some sections to be present and each section will require some specific parameters. Depending on the options, other sections might be required/used, but we'll come back to this later. These are the mandatory sections:\n",
    "- `[general]`\n",
    "- `[reader]`\n",
    "- `[rebin]`\n",
    "- `[normalizer]`\n",
    "- `[stacker]`\n",
    "- `[writer]`\n",
    "\n",
    "We now revise the arguments of the different sections. Note that if other arguments are passed, they will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General section\n",
    "\n",
    "The general section sets common options that are not really used by any of the classes specifically. You can get the up-to-date list of arguments for this section by running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`overwrite`: This variable specifies where to save the results. **Type: str**, **Required: no**, **Default: False**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`logging level console`: This variable controls console messages. Must be one of CRITICAL, ERROR, WARNING_OK, WARNING, INFO, PROGRESS, DEBUG, NOTSET **Type: str**, **Required: no**, **Default: PROGRESS**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`logging level file`: This variable controls log messages. Must be one of CRITICAL, ERROR, WARNING_OK, WARNING, INFO, PROGRESS, DEBUG, NOTSET. Ignored if `log` is `None` **Type: str**, **Required: no**, **Default: PROGRESS**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`log`: If a log file is passed, print messages also there **Type: str**, **Required: no**, **Default: run.log**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`output directory`: This variable specifies where to save the results. **Type: str**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`num processors`: Number of processors to be used for multiprocessed tasks (e.g. data i/o, expected flux). 0 for using half the processes available on the machine (subprocess will take its default value). **Type: int or None**, **Required: no**, **Default: 0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`run type`: Run type. Must be one of 'normal' 'merge norm factors' 'merge stack'. **Type: str**, **Required: no**, **Default: normal**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stacking.configuration_help import print_general_options\n",
    "print_general_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reader section\n",
    "The reader section controls which type of data are we going to load. For example, we might want to run stacking on SDSS spectra or on DESI data. You can get the current list of available readers by running the following cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr16Reader\n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_classes\n",
    "print_classes(\"readers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the class description run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class Dr16Reader"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reads the spectra from SDSS DR16 and formats its data as a list of\n",
      "    Spectrum instances.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see Reader in stacking/reader.py)\n",
      "    __init__\n",
      "    __parse_config\n",
      "    read_data\n",
      "    read_drq_catalogue\n",
      "    read_from_spec\n",
      "    read_from_spplate\n",
      "    read_spall\n",
      "    trim_catalogue\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see Reader in stacking/data.py)\n",
      "\n",
      "    best_obs: bool\n",
      "    If True, reads only the best observation for quasars with repeated\n",
      "    observations\n",
      "\n",
      "    max_balnicity_index: float or None\n",
      "    Maximum value allowed for the Balnicity Index to keep the quasar.\n",
      "    None for no maximum\n",
      "\n",
      "    max_num_spec: int or None\n",
      "    Maximum number of spectra to load. None for no maximum.\n",
      "    Multiple spectra comming from the same line of sight are not counted here\n",
      "\n",
      "    drq_filename: str\n",
      "    Filename of the DRQ catalogue\n",
      "\n",
      "    keep_bal: bool\n",
      "    If False, remove the quasars flagged as having a Broad Absorption\n",
      "    Line. Ignored if max_balnicity_index is not None\n",
      "\n",
      "    logger: logging.Logger\n",
      "    Logger object\n",
      "\n",
      "    read_mode: str\n",
      "    Reading mode. Currently supported reading modes are \"spplate\" and \"spec\"\n",
      "\n",
      "    skip_n_first_spec: int\n",
      "    Skip the N first spectra in the catalogue\n",
      "\n",
      "    spall: str\n",
      "    Path to the spAll file required for multiple observations\n",
      "\n",
      "    z_max: float\n",
      "    Maximum redshift. Quasars with redshifts higher than or equal to\n",
      "    z_max will be discarded\n",
      "\n",
      "    z_min: float\n",
      "    Minimum redshift. Quasars with redshifts lower than z_min will be\n",
      "    discarded\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class Reader"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract class to define the readers skeleton\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    __init__\n",
      "    __parse_config\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    catalogue: astropy.table.Table\n",
      "    Metadata associated with the spectra. Ordering should be maintained\n",
      "    between spectra and catalogue\n",
      "\n",
      "    input_directory: str\n",
      "    The input directory\n",
      "\n",
      "    spectra: list of Spectrum\n",
      "    The read spectra. Ordering should be maintained\n",
      "    between spectra and catalogue\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_description\n",
    "print_class_description(\"Dr16Reader\", \"readers\") # this should be changed with your reader class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now access the options of a given class by executing the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class Dr16Reader"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`input directory`: Directory containing the spectra. **Type: str**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`best obs`: If True, reads only the best observation for quasars with repeated observations. **Type: bool**, **Required: no**, **Default: False**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`drq catalogue`: Filename of the DRQ catalogue. **Type: str**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`keep BAL`: If False, remove the quasars flagged as having a Broad Absorption Line. Ignored if max_balnicity_index is not None. **Type: bool**, **Required: no**, **Default: False**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`max Balnicity Index`: Maximum value allowed for the Balnicity Index to keep the quasar. None for no maximum. **Type: float or None**, **Required: no**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`max num spec`: Maximum number of spectra to load. None for no maximum. Multiple spectra comming from the same line of sight are not counted here. **Type: int or None**, **Required: no**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`read mode`: Reading mode. Currently supported reading modes are 'spplate' and 'spec'. **Type: str**, **Required: no**, **Default: spplate**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`skip N first spec`: Skip the N first spectra in the catalogue. **Type: int**, **Required: no**, **Default: 0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`spAll`: Path to the spAll file required for multiple observations. **Type: str**, **Required: no**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`z min`: Minimum redshift. Quasars with redshifts lower than z_min will be discarded. **Type: float**, **Required: no**, **Default: 0.0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`z max`: Maximum redshift. Quasars with redshifts higher than or equal to z_max will be discarded. **Type: float**, **Required: no**, **Default: 10.0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_options\n",
    "print_class_options(\"Dr16Reader\", \"readers\") # this should be changed with your reader class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebin section\n",
    "The rebin section controls the parameters for the common wavelength grid to where we rebin all objects before actually stacking them. This is managed by the class `Rebin` whose up-to-date options can be listed running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class Rebin"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`max wavelength`: Maximum wavelength of the common wavelength grid. **Type: float**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`min wavelength`: Minimum wavelength of the common wavelength grid. **Type: float**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`step type`: Type of step in the common grid. 'lin' means the common grid is equally spaced in wavelength. 'log' means it is equally spaced in the logarithm of the wavelength. **Type: string**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`step wavelength`: Step in the common grid. **Type: float**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_options\n",
    "print_class_options(\"Rebin\", \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizer section\n",
    "The normalizer section controls the parameters for the normalization procedure. Different data may use different normalization procedures. You can get the current list of available normalizers by running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialMultipleRegionsNormalization\n",
      "MergeMultipleRegionsNormalization\n",
      "NoNormalization\n",
      "MultipleRegionsNormalization\n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_classes\n",
    "print_classes(\"normalizers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the class description run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class MergeMultipleRegionsNormalization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This class is set to compute the normalization factors using multiple\n",
      "    normalization regions.\n",
      "\n",
      "    Contrary to the parent class, here we assume we have a set of partial runs.\n",
      "    They are merged and the correction factors are computed.\n",
      "    Thus, after computing the normalization factors, they will be saved and the\n",
      "    program will end.\n",
      "\n",
      "    To be implemented:\n",
      "    Optionally combine with normalization factors loaded from previous runs\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see MultipleRegionsNormalization in stacking/normalizers/multiple_regions_normalization.py)\n",
      "    __init__\n",
      "    __parse_config\n",
      "    compute_norm_factors\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see MultipleRegionsNormalization in stacking/normalizers/multiple_regions_normalization.py)\n",
      "\n",
      "    folders_list: list of str\n",
      "    List of folders where the partial runs are stored\n",
      "\n",
      "    logger: logging.Logger\n",
      "    Logger object\n",
      "\n",
      "    save_on_list: bool\n",
      "    If True, save the normalization factors on the list of folders\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class MultipleRegionsNormalization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This class is set to compute the normalization factors using multiple\n",
      "    normalization regions\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    __init__\n",
      "    __parse_config\n",
      "    compute_normalisation_factors\n",
      "    normalize_spectrum\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    correction_factors: array of float\n",
      "    Correction factors that relate the different intervals\n",
      "\n",
      "    intervals:  array of (float, float)\n",
      "    Array containing the selected intervals. Each item must contain\n",
      "    two floats signaling the starting and ending wavelength of the interval.\n",
      "    Naturally, the starting wavelength must be smaller than the ending wavelength.\n",
      "\n",
      "    log_directory: str\n",
      "    Directory where log data is saved. Normalization factors will be saved there\n",
      "\n",
      "    logger: logging.Logger\n",
      "    Logger object\n",
      "\n",
      "    main_interval: int\n",
      "    Number of main normalizeation interval\n",
      "\n",
      "    norm_factor: pd.DataFrame\n",
      "    Pandas DataFrame with the normalization factors\n",
      "\n",
      "    num_intervals: int\n",
      "    Number of intervals\n",
      "\n",
      "    save_format: str\n",
      "    Saving format, e.g. 'csv', 'txt', 'fits' or 'fits.gz'\n",
      "\n",
      "    sigma_i: float\n",
      "    A correction to the weights so that pixels with very small variance do not\n",
      "    dominate. Weights are computed as w = 1 / (sigma^2 + sigma_i^2)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class Normalizer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract class to define the normalizer skeleton\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    compute_normalisation_factors\n",
      "    normalize_spectrum\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_description\n",
    "print_class_description(\"MergeMultipleRegionsNormalization\", \"normalizers\") # this should be changed with your normalizer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now access the options of a given class by executing the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class PartialMultipleRegionsNormalization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`intervals`: Normalzation intervals. Expected format is 'start0 - end0, start1 - end1, ..., startN - endN' where startX and endX are positive numbers. **Type: str**, **Required: no**, **Default: 1300 - 1500, 2000 - 2600, 4400 - 4800**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`log directory`: Directory where log data is saved. Normalization factors will be saved there. **Type: str**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`main interval`: Number of main normalization interval. **Type: int**, **Required: no**, **Default: 1**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`min nrom sn`: Minimum S/N for the normalization factor to be considered. **Type: float**, **Required: no**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`num processors`: Number of processors to use. **Type: int**, **Required: no**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`save format`: Saving format, e.g. 'csv', 'txt', 'fits' or 'fits.gz'. **Type: str**, **Required: no**, **Default: fits.gz**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`sigma_I`: Additional variance added to the inverse variance of the spectra to suppress the brightest pixels. **Type: float**, **Required: no**, **Default: 0.05**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`compute correction factors flag`: If True, compute the correction factors. **Type: bool**, **Required: no**, **Default: False**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_options\n",
    "print_class_options(\"PartialMultipleRegionsNormalization\", \"normalizers\") # this should be changed with your normalizer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacker section\n",
    "The stacker section controls the stacking parameters. Different stacking classes use different procedures: mean, median, multiple stack, ... You can get the current list of available normalizers by running the following cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BootstrapMeanStacker\n",
      "SplitStacker\n",
      "MergeSplitStacker\n",
      "MergeStacker\n",
      "MedianStacker\n",
      "BootstrapSplitMeanStacker\n",
      "MergeMedianStacker\n",
      "MergeSplitMeanStacker\n",
      "MergeBootstrapMeanStacker\n",
      "MergeMeanStacker\n",
      "MergeSplitMedianStacker\n",
      "BootstrapStacker\n",
      "SplitMedianStacker\n",
      "SplitMeanStacker\n",
      "MeanStacker\n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_classes\n",
    "print_classes(\"stackers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the class description run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class MergeSplitMedianStacker"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to compute multiple stacks splitting on one\n",
      "    or more properties of the spectra. Uses class MergeMedianStacker\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see MergeSplitStacker in stacking/stackers/merge_split_stacker.py)\n",
      "    (see MergeMeanStacker in stacking/stackers/merge_median_stacker.py)\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see MergeSplitStacker in stacking/stackers/merge_split_stacker.py)\n",
      "    (see MergeMeanStacker in stacking/stackers/merge_median_stacker.py)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class MergeSplitStacker"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract class to compute multiple stacks splitting on one\n",
      "    or more properties of the spectra using different partial runs\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see MergeStacker in stacking/stackers/merge_stacker.py)\n",
      "    __init__\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see MergeStacker in stacking/stackers/merge_stacker.py)\n",
      "\n",
      "    groups_info: pd.DataFrame\n",
      "    DataFrame containing the group information\n",
      "\n",
      "    num_groups: int\n",
      "    Number of groups the data is split on\n",
      "\n",
      "    split_catalogue: pd.DataFrame\n",
      "    The catalogue to be split\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class MergeMedianStacker"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to compute the satck using the median of different partial runs\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see MergeStacker in stacking/stacker.py)\n",
      "    (see MedianStacker in stacking/stackers/median_stacker.py)\n",
      "    stack\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see MergeStacker in stacking/stacker.py)\n",
      "    (see MedianStacker in stacking/stackers/median_stacker.py)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class MergeStacker"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract class to compute the satck using different partial runs\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see Stacker in stacking/stacker.py)\n",
      "    __init__\n",
      "    __parse_config\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see Stacker in stacking/stacker.py)\n",
      "\n",
      "    hdu_name: str\n",
      "    Name of the HDU to containing the spectra to load. Should be a valid HDU in each of the files in stack_list\n",
      "\n",
      "    stack_list: list of str\n",
      "    List of files containing the individual stacks to be merged\n",
      "\n",
      "    stacks: list of (array of float, array of float)\n",
      "    Individual stacks to be merged. Each item contains a tuple with the flux\n",
      "    and weight arrays\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class MedianStacker"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to compute the satck using the median of the different spectra\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see Stacker in stacking/stacker.py)\n",
      "    stack\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see Stacker in stacking/stacker.py)\n",
      "\n",
      "    weighted: boolean\n",
      "    If True, then compute the weighted median. Otherwise, compute the regular\n",
      "    median\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class Stacker"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract class to define the normalizer skeleton\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    __init__\n",
      "    stack\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    stacked_flux: array of float\n",
      "    The stacked flux\n",
      "\n",
      "    stacked_weight: array of float\n",
      "    The sum of weights associated with each flux\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_description\n",
    "print_class_description(\"MergeSplitMedianStacker\", \"stackers\") # this should be changed with your stacker class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now access the options of a given class by executing the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class MergeSplitMedianStacker"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`hdu name`: Name of the HDU to containing the spectra to load. Should be a valid HDU in each of the files in stack_list. **Type: str**, **Required: no**, **Default: STACK**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`stack list`: List of files containing the individual stacks to be merged. **Type: str**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`weighted`: If True, then compute the weighted median. Otherwise, compute the regular median. **Type: bool**, **Required: no**, **Default: False**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_options\n",
    "print_class_options(\"MergeSplitMedianStacker\", \"stackers\") # this should be changed with your stacker class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writer section \n",
    "The writer section controls the saving parameters. There are several writing classes that adapt to the different stack types. The class used is automatically picked up by the specified stacker. You can get the current list of available normalizers by running the following cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitWriter\n",
      "BootstrapWriter\n",
      "StandardWriter\n",
      "BootstrapSplitWriter\n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_classes\n",
    "print_classes(\"writers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out which writer is being loaded you can run the cell below with your chosen stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitWriter\n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_selected_writer\n",
    "print_selected_writer(\"MergeSplitMedianStacker\") # this should be changed with your stacker class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the class description run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class SplitWriter"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to write the satck results using splits\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    (see Writer in stacking/writer.py)\n",
      "    __init__\n",
      "    write_results\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    (see Writer in stacking/writer.py)\n",
      "\n",
      "    logger: logging.Logger\n",
      "    Logger object\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Class Writer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract class to write the results\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    __init__\n",
      "    __parse_config\n",
      "    write_results\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    output_directory: str\n",
      "    The output directory\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_description\n",
    "print_class_description(\"SplitWriter\", \"writers\") # this should be changed with your writer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now access the options of a given class by executing the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Class SplitWriter"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`output directory`: Directory to save the results. **Type: str**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`output file`: Filename to save the results. **Type: str**, **Required: yes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`overwrite`: Overwrite the output file if it exists. **Type: bool**, **Required: no**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stacking.configuration_help import print_class_options\n",
    "print_class_options(\"SplitWriter\", \"writers\") # this should be changed with your writer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "You can see some examples of configuration files under the `examples` folder  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "777432c535f60d1b96111a5bbd84f4376982b3bbbbdb21ae46e47c84457b736c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
